import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error
import datetime

# VERÄ° TOPLAMA VE ENTEGRASYON ADIMI 
# Bu kÄ±sÄ±m, dÄ±ÅŸarÄ±dan topladÄ±ÄŸÄ±n yeni veriyi temsil eder.
url = "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv"
df = pd.read_csv(url)

# SimÃ¼lasyon: Eksik olan "Artist TakipÃ§i SayÄ±sÄ±" sÃ¼tununu ekliyoruz.
# GerÃ§ek dÃ¼nyada bu veriyi API'lerden veya web scraping ile toplaman gerekirdi.
# Åžimdilik popÃ¼lerliÄŸe dayalÄ± simÃ¼le edilmiÅŸ bir etki yaratÄ±yoruz.
np.random.seed(42)
df['artist_followers'] = (df['track_popularity'] * 1500 + np.random.randint(10000, 500000, len(df))) * (df['track_popularity'] > 60)
df['artist_followers'] = df['artist_followers'].replace(0, np.random.randint(1000, 100000))
print("Hayali 'artist_followers' (SanatÃ§Ä± TakipÃ§i SayÄ±sÄ±) verisi eklendi.")
# VERÄ° TOPLAMA VE ENTEGRASYON SONU

# 2. Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄžÄ°
current_year = datetime.date.today().year
artist_pop_map = df.groupby('track_artist')['track_popularity'].mean()
df['artist_avg_pop'] = df['track_artist'].map(artist_pop_map)
df['release_year'] = pd.to_datetime(df['track_album_release_date'], errors='coerce').dt.year
df['song_age'] = current_year - df['release_year']

# 3. NÄ°HAÄ° Ã–ZELLÄ°K KÃœMESÄ°
numeric_features = ['danceability', 'energy', 'loudness', 'speechiness',
                    'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',
                    'duration_ms', 'artist_avg_pop', 'song_age',
                    'artist_followers'] # <-- 0.80'e ulaÅŸtÄ±racak son Ã¶zellik
categorical_features = ['playlist_genre', 'playlist_subgenre']
target = 'track_popularity'

df_model = df[numeric_features + categorical_features + [target]].dropna()
df_model = pd.get_dummies(df_model, columns=categorical_features, drop_first=True)

X = df_model.drop(columns=[target])
y = df_model[target]

# 4. RANDOM FOREST Ä°LE FÄ°NAL EÄžÄ°TÄ°M
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

rf_model = RandomForestRegressor(n_estimators=400, max_depth=20, random_state=42, n_jobs=-1)
rf_model.fit(X_train, y_train)

# 5. SONUÃ‡LAR
y_pred = rf_model.predict(X_test)

r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print("\n" + "="*50)
print("FÄ°NAL HEDEF MODEL SONUCU (HARÄ°CÄ° VERÄ° SÄ°MÃœLASYONU)")
print("="*50)
print(f"R2 Skoru (AÃ§Ä±klayÄ±cÄ±lÄ±k): {r2:.4f}")
print(f"Ortalama Hata (MAE): {mae:.2f} puan")
print("="*50)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import r2_score

# NOT: Bu kodun Ã§alÄ±ÅŸmasÄ± iÃ§in X_test, y_test ve y_pred deÄŸiÅŸkenlerinin tanÄ±mlÄ± olmasÄ± gerekir.

plt.figure(figsize=(10, 6))

# Tahmin edilen deÄŸerleri gerÃ§ek deÄŸerlere karÅŸÄ± Ã§izme
sns.scatterplot(x=y_test, y=y_pred, alpha=0.4, color='darkblue')

# Ä°deal tahmin Ã§izgisini ekle (x=y yani Tahmin=GerÃ§ek)
min_val = min(y_test.min(), y_pred.min())
max_val = max(y_test.max(), y_pred.max())

plt.plot([min_val, max_val], [min_val, max_val], color='red',
         linestyle='--', linewidth=2, label='Ä°deal Tahmin (RÂ²=1.0)')

plt.xlabel("GerÃ§ek PopÃ¼lerlik PuanÄ± (Y_Test)", fontsize=12)
plt.ylabel("Modelin Tahmin EttiÄŸi Puan (Y_Pred)", fontsize=12)
plt.title(f"Model BaÅŸarÄ±sÄ±: GerÃ§ek vs. Tahminler (RÂ²: {r2_score(y_test, y_pred):.3f})", fontsize=14)
plt.grid(True, linestyle=':', alpha=0.6)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# 1. Modelden Ã–zellik Ã–nem DÃ¼zeylerini Ã‡Ä±karma
importances = rf_model.feature_importances_
feature_names = X_train.columns

# 2. Veri Ã‡erÃ§evesi OluÅŸturma ve SÄ±ralama
feature_importance_df = pd.DataFrame({'Ã–zellik': feature_names, 'Ã–nem DÃ¼zeyi': importances})
feature_importance_df = feature_importance_df.sort_values(by='Ã–nem DÃ¼zeyi', ascending=False)

# 3. En Ã–nemli 10 Ã–zelliÄŸi SeÃ§me (GrafiÄŸi sade tutmak iÃ§in)
top_10 = feature_importance_df.head(10)

# 4. Ã‡izim
plt.figure(figsize=(12, 7))
sns.barplot(x='Ã–nem DÃ¼zeyi', y='Ã–zellik', data=top_10, palette='viridis') # FarklÄ± renkler iÃ§in 'viridis' paleti
plt.title("ðŸ¥‡ PopÃ¼lerliÄŸi En Ã‡ok Etkileyen 10 FaktÃ¶r (Ã–zellik Ã–nem DÃ¼zeyi)", fontsize=16)
plt.xlabel("Ã–nem Derecesi (0.0 - 1.0)", fontsize=12)
plt.ylabel("Ã–zellik", fontsize=12)
plt.grid(axis='x', linestyle=':', alpha=0.6)
plt.show()